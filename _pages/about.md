---
permalink: /
title: "Personal Introduction"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

- Hello! My name is **Junbing Yan (ä¸¥ä¿Šå†°)**.
- I'm a Master student at East China Normal University (ECNU) (from Sep. 2021 to Jun. 2024) in Shanghai supervised by [Prof. Wei Zhang](https://weizhangltt.github.io/) majoring Recommadation System and Natural Language Processing (NLP).
- Currently, I am working as an Algorithm Engineer at Alibaba Cloud's PAI Platform, where my main focus is on knowledge distillation techniques for large models (transferring knowledge from large models to smaller ones to reduce deployment costs and improve performance) and the practical implementation of agent-related applications. I have been in this role since June 2024.
- My research points consist of Large Language Models (LLMs), Knowledge Distillation and Complex Reasoning in LLMs.
- I have published some research papers at ACL, EMNLP, WWW, etc., including Knowledge-enhanced Pre-trained Language Models, Knowledge Distillation for Large Models and Enhancing Mathematical and Logical Reasoning in Large Models. More details can be found in [Publications](https://andrewyan123.github.io/publications/) and [Projects](https://andrewyan123.github.io/projects/).
- I had some internship experiences, including working as a research intern at Alibaba PAI Platform (Aug. 2022 - Jun. 2024), where I participated in the development of the EasyNLP project and conducted research related to large knowledge models.

News
======

* [2025-05-29] The EasyDistill has been released in [https://github.com/modelscope/easydistill](https://github.com/modelscope/easydistill). ðŸ”¥ðŸ”¥ðŸ”¥
* [2025-05-20] Our reasoning dataset and models have been released in HuggingFace: [https://huggingface.co/datasets/alibaba-pai/OmniThought](https://huggingface.co/datasets/alibaba-pai/OmniThought) and [https://huggingface.co/alibaba-pai/DistilQwen-ThoughtX-32B](https://huggingface.co/alibaba-pai/DistilQwen-ThoughtX-32B). ðŸ”¥ðŸ”¥ðŸ”¥
* [2025-05-16] Our new paper has been released in ArXiv: [Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations](https://arxiv.org/abs/2505.10937). ðŸ”¥ðŸ”¥ðŸ”¥
* [2025-05-11] Our one paper has been accepted to ACL 2025.