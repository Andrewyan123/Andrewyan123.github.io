---
permalink: /
title: "Personal Introduction"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

- Hello! My name is **Junbing Yan (ä¸¥ä¿Šå†°)**.
- Currently, I am working as an AI Algorithm Engineer at Alibaba Cloud's PAI Platform (from Jun. 2024), where my main focus is on knowledge distillation techniques for large models (transferring knowledge from large models to smaller ones to reduce deployment costs and improve performance) and the practical implementation of agent-related applications.
- I graduated with a Master's degree from East China Normal University (ECNU) in Shanghai (Sep. 2021 - Jun. 2024) supervised by [Prof. Wei Zhang](https://weizhangltt.github.io/) majoring Recommadation System and Natural Language Processing (NLP).
- My research points consist of Large Language Models (LLMs), Knowledge Distillation and Complex Reasoning in LLMs.
- I have published some research papers at ACL, EMNLP, WWW, etc., including Knowledge-enhanced Pre-trained Language Models, Knowledge Distillation for Large Models and Enhancing Mathematical and Logical Reasoning in Large Models. More details can be found in [Publications](https://andrewyan123.github.io/publications/) and [Projects](https://andrewyan123.github.io/projects/).
- I had some internship experiences, including working as a research intern at Alibaba PAI Platform (Aug. 2022 - Jun. 2024), where I participated in the development of the EasyNLP project and conducted research related to large knowledge models.

News
======

* [2025-05-29] The EasyDistill has been released in [https://github.com/modelscope/easydistill](https://github.com/modelscope/easydistill). ðŸ”¥ðŸ”¥ðŸ”¥
* [2025-05-20] Our reasoning dataset and models have been released in HuggingFace: [https://huggingface.co/datasets/alibaba-pai/OmniThought](https://huggingface.co/datasets/alibaba-pai/OmniThought) and [https://huggingface.co/alibaba-pai/DistilQwen-ThoughtX-32B](https://huggingface.co/alibaba-pai/DistilQwen-ThoughtX-32B). ðŸ”¥ðŸ”¥ðŸ”¥
* [2025-05-16] Our new paper has been released in ArXiv: [Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations](https://arxiv.org/abs/2505.10937). ðŸ”¥ðŸ”¥ðŸ”¥
* [2025-05-11] Our one paper has been accepted to ACL 2025.